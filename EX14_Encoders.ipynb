{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NikNord174/Neural_Networks_for_Science/blob/master/EX14_Encoders.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v3c1gN9HUDMH"
      },
      "source": [
        "## Импорты, функции из занятия"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BGDgl6XfUDMK"
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set_style(\"whitegrid\")\n",
        "\n",
        "from itertools import chain, product\n",
        "\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g4he6saCUDML"
      },
      "source": [
        "def plot_manifold(latent_r, labels=None, alpha=0.5):\n",
        "    plt.figure(figsize=(10,10))\n",
        "    if labels is None:\n",
        "      plt.scatter(latent_r[:, 0], latent_r[:, 1], cmap=\"tab10\", alpha=0.9)\n",
        "    else:\n",
        "      plt.scatter(latent_r[:, 0], latent_r[:, 1], c=labels, cmap=\"tab10\", alpha=0.9)\n",
        "      plt.colorbar()\n",
        "    plt.show()\n",
        "\n",
        "# plotting reconstructed and noised images\n",
        "def plot_digits(*args, invert_colors=True, digit_size = 28, name=None):\n",
        "    args = [x.squeeze() for x in args]\n",
        "    n = min([x.shape[0] for x in args])\n",
        "    figure = np.zeros((digit_size * len(args), digit_size * n))\n",
        "\n",
        "    for i in range(n):\n",
        "        for j in range(len(args)):\n",
        "            figure[j * digit_size: (j + 1) * digit_size,\n",
        "                   i * digit_size: (i + 1) * digit_size] = args[j][i].squeeze()\n",
        "\n",
        "    if invert_colors:\n",
        "        figure = 1-figure\n",
        "\n",
        "    plt.figure(figsize=(2*n, \n",
        "                        2*len(args))\n",
        "              )\n",
        "    \n",
        "    plt.imshow(figure,\n",
        "               cmap='Greys_r',\n",
        "               clim=(0,1))\n",
        "    \n",
        "    plt.grid(False)\n",
        "    ax = plt.gca()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "    if name is not None:\n",
        "        plt.savefig(name)\n",
        "    plt.show()\n",
        "\n",
        "def train(enc, \n",
        "          dec,\n",
        "          loader, \n",
        "          optimizer, \n",
        "          single_pass_handler, \n",
        "          loss_handler,\n",
        "          epoch, \n",
        "          log_interval=500):\n",
        "    for batch_idx, (data, lab) in enumerate(loader):\n",
        "        batch_size = data.size(0)\n",
        "        optimizer.zero_grad()\n",
        "        data = data.to(device)\n",
        "        lab = lab.to(device)\n",
        "\n",
        "        latent, output = single_pass_handler(encoder, decoder, data, lab)\n",
        "\n",
        "        loss = loss_handler(data, output, latent)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if batch_idx % log_interval == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(data), len(loader.dataset),\n",
        "                100. * batch_idx / len(loader), loss.item()))\n",
        "\n",
        "# return reconstructed image, use to compute loss          \n",
        "def ae_pass_handler(encoder, decoder, data, *args, **kwargs):\n",
        "    latent = encoder(data)\n",
        "    recons = decoder(latent)\n",
        "    return latent, recons\n",
        "\n",
        "# loss function  \n",
        "def ae_loss_handler(data, recons, *args, **kwargs):\n",
        "    return F.binary_cross_entropy(recons, data)\n",
        "\n",
        "# return result in numpy to visualization\n",
        "def run_eval(encoder, \n",
        "             decoder, \n",
        "             loader, \n",
        "             single_pass_handler,\n",
        "             return_real=True, \n",
        "             return_recontr=True,\n",
        "             return_latent=True,\n",
        "             return_labels=True):\n",
        "  \n",
        "    if return_real:\n",
        "        real = []\n",
        "    if return_recontr:\n",
        "        reconstr = []\n",
        "    if return_latent:\n",
        "        latent = []\n",
        "    if return_labels:\n",
        "        labels = []\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (data, lab) in enumerate(loader):  \n",
        "            if return_labels:\n",
        "                labels.append(lab.numpy())\n",
        "            if return_real:\n",
        "                real.append(data.numpy())\n",
        "            \n",
        "            data = data.to(device)\n",
        "            lab = lab.to(device)\n",
        "            rep, rec = single_pass_handler(encoder, decoder, data, lab)\n",
        "            if return_latent:\n",
        "                latent.append(rep.to('cpu').numpy())\n",
        "            if return_recontr:\n",
        "                reconstr.append(rec.to('cpu').numpy())\n",
        "    \n",
        "    result = {}\n",
        "    if return_real:\n",
        "        real = np.concatenate(real)\n",
        "        result['real'] = real.squeeze()\n",
        "    if return_latent:\n",
        "        latent = np.concatenate(latent)\n",
        "        result['latent'] = latent\n",
        "    if return_recontr:\n",
        "        reconstr = np.concatenate(reconstr)\n",
        "        result['reconstr'] = reconstr.squeeze()\n",
        "    if return_labels:\n",
        "        labels = np.concatenate(labels)\n",
        "        result['labels'] = labels\n",
        "    return result\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fRdbhk_FUDMN"
      },
      "source": [
        "#handson-ml2\n",
        "\n",
        "import matplotlib as mpl\n",
        "def plot_percent_hist(ax, data, bins):\n",
        "    counts, _ = np.histogram(data, bins=bins)\n",
        "    widths = bins[1:] - bins[:-1]\n",
        "    x = bins[:-1] + widths / 2\n",
        "    ax.bar(x, counts / len(data), width=widths*0.8)\n",
        "    ax.xaxis.set_ticks(bins)\n",
        "    ax.yaxis.set_major_formatter(mpl.ticker.FuncFormatter(\n",
        "        lambda y, position: \"{}%\".format(int(np.round(100 * y)))))\n",
        "    ax.grid(True)\n",
        "\n",
        "  \n",
        "def plot_activations_histogram(activations, height=1, n_bins=10):\n",
        "    activation_means = activations.mean(axis=0)\n",
        "    \n",
        "    mean = activation_means.mean()\n",
        "    bins = np.linspace(0, 1, n_bins + 1)\n",
        "\n",
        "    fig, [ax1, ax2] = plt.subplots(figsize=(10, 3), nrows=1, ncols=2, sharey=True)\n",
        "    plot_percent_hist(ax1, activations.ravel(), bins)\n",
        "    ax1.plot([mean, mean], [0, height], \"k--\", label=\"Overall Mean = {:.2f}\".format(mean))\n",
        "    ax1.legend(loc=\"upper center\", fontsize=14)\n",
        "    ax1.set_xlabel(\"Activation\")\n",
        "    ax1.set_ylabel(\"% Activations\")\n",
        "    ax1.axis([0, 1, 0, height])\n",
        "    plot_percent_hist(ax2, activation_means, bins)\n",
        "    ax2.plot([mean, mean], [0, height], \"k--\")\n",
        "    ax2.set_xlabel(\"Neuron Mean Activation\")\n",
        "    ax2.set_ylabel(\"% Neurons\")\n",
        "    ax2.axis([0, 1, 0, height])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kDPbZ_OTUDMO"
      },
      "source": [
        "class AddGaussianNoise(): # add noise\n",
        "    def __init__(self, mean=0., std=1.):\n",
        "        self.std = std\n",
        "        self.mean = mean\n",
        "        \n",
        "    def __call__(self, tensor):\n",
        "        return tensor + torch.randn(tensor.size()) * self.std + self.mean\n",
        "    \n",
        "    def __repr__(self):\n",
        "        return self.__class__.__name__ + '(mean={0}, std={1})'.format(self.mean, self.std)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1AU364LyUDMO"
      },
      "source": [
        "# autoencoder model\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, latent_size):\n",
        "        super().__init__()\n",
        "        self.latent_size = latent_size\n",
        "        hidden_dims = [32, 64, 128, 256, 512]\n",
        "\n",
        "        # Build Encoder\n",
        "        modules = []\n",
        "        in_channels = 1\n",
        "        for h_dim in hidden_dims[:-1]:\n",
        "            modules.append(\n",
        "                nn.Sequential(\n",
        "                    nn.Conv2d(in_channels=in_channels,\n",
        "                              out_channels=h_dim,\n",
        "                              kernel_size= 3, stride= 2 , padding  = 1),\n",
        "                    nn.BatchNorm2d(h_dim),\n",
        "                    nn.LeakyReLU())\n",
        "            )\n",
        "            in_channels = h_dim\n",
        "\n",
        "        modules.append(\n",
        "                nn.Sequential(\n",
        "                    nn.Conv2d(in_channels=256,\n",
        "                              out_channels=512,\n",
        "                              kernel_size= 1),\n",
        "                    nn.BatchNorm2d(512),\n",
        "                    nn.LeakyReLU())\n",
        "        )\n",
        "        modules.append(nn.Flatten())\n",
        "        modules.append(nn.Linear(hidden_dims[-1] * 4, latent_size))\n",
        "\n",
        "        self.encoder = nn.Sequential(*modules)      \n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = self.encoder(x)\n",
        "        return x\n",
        "        \n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, latent_size):\n",
        "        super().__init__()\n",
        "\n",
        "        hidden_dims = [512, 256, 128, 64, 32]\n",
        "        self.linear = nn.Linear(in_features=latent_size, \n",
        "                                out_features=hidden_dims[0])\n",
        "        \n",
        "        modules = []\n",
        "        for i in range(len(hidden_dims) - 1):\n",
        "            modules.append(\n",
        "                nn.Sequential(\n",
        "                    nn.ConvTranspose2d(hidden_dims[i],\n",
        "                                       hidden_dims[i + 1],\n",
        "                                       kernel_size=3,\n",
        "                                       stride = 2,\n",
        "                                       padding=1,\n",
        "                                       output_padding=1),\n",
        "                    nn.BatchNorm2d(hidden_dims[i + 1]),\n",
        "                    nn.LeakyReLU())\n",
        "            )\n",
        "\n",
        "\n",
        "        modules.append(nn.Sequential(\n",
        "                            nn.ConvTranspose2d(hidden_dims[-1],\n",
        "                                               hidden_dims[-1],\n",
        "                                               kernel_size=3,\n",
        "                                               stride=2,\n",
        "                                               padding=1,\n",
        "                                               output_padding=1),\n",
        "                            nn.BatchNorm2d(hidden_dims[-1]),\n",
        "                            nn.LeakyReLU(),\n",
        "                            nn.Conv2d(hidden_dims[-1], out_channels= 1,\n",
        "                                      kernel_size= 7, padding= 1),\n",
        "                            nn.Sigmoid()))\n",
        "\n",
        "        self.decoder = nn.Sequential(*modules)   \n",
        "\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.linear(x)\n",
        "        x = x.view(-1, 512, 1, 1)\n",
        "        x = self.decoder(x)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FuLXJgYSUDMP"
      },
      "source": [
        "# Задание 1. Автоэнкодер для KMNIST c MSE-loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7jxm0J0jUDMP"
      },
      "source": [
        "\n",
        "В этом задании обучайте автоэнкодер на датасете KMNIST:\n",
        "\n",
        "* Используйте энкодер и декодер из лекции\n",
        "* Уберите из декодера сигмоиду в конце\n",
        "* Используйте MSE-loss между реальным и восстановленным изображением\n",
        "\n",
        "\n",
        "\n",
        "Как выглядит латентное представление? \n",
        "\n",
        "Разделяются ли в нем классы? \n",
        "\n",
        "Далее:\n",
        "\n",
        "\n",
        "*   Обучите автоэнкодер с размером латентного слоя 30\n",
        "*   Продемонстрируйте восстановление автоэнкодером переданных ему изображений\n",
        "\n",
        "Чем восстановление отличается от восстановления автоенкодером, обученном в лекции? \n",
        " \n",
        "Что не нравится в полученных востановленных изображениях?\n",
        "\n",
        "Напишите выводы"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OU66K1q2UDMQ"
      },
      "source": [
        "root = './data'\n",
        "\n",
        "train_set = dset.KMNIST(root=root, \n",
        "                       train=True, \n",
        "                       transform=torchvision.transforms.ToTensor(),\n",
        "                       download=True)\n",
        "test_set = dset.KMNIST(root=root, \n",
        "                      train=False,\n",
        "                      transform=torchvision.transforms.ToTensor(),\n",
        "                      download=True)\n",
        "\n",
        "test_noise_set = dset.KMNIST(root=root, \n",
        "                      train=False,\n",
        "                      transform=torchvision.transforms.Compose([\n",
        "                          torchvision.transforms.ToTensor(),\n",
        "                          AddGaussianNoise(0., 0.30)\n",
        "                      ]),\n",
        "                      download=True)\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    train_set, \n",
        "    batch_size=64,\n",
        "    shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    train_set, \n",
        "    batch_size=64,\n",
        "    shuffle=False)\n",
        "\n",
        "test_noised_dataloader = torch.utils.data.DataLoader(\n",
        "    torch.utils.data.Subset(test_noise_set, list(range(64))),\n",
        "    batch_size=64, \n",
        "    shuffle=False)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "do4iRRZXUDMQ"
      },
      "source": [
        "# enter your code here\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LytMWvu1UDMR"
      },
      "source": [
        "# Задание 2. Разреженный autoencoder с KL-loss\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "77YJERlCUDMR"
      },
      "source": [
        "\n",
        "На занятии мы обсуждали, что разреженный автоэнкодер можно делать двумя путями - при помощи L1 и при помощи KL лосса. На занятии мы сделали с L1  лоссом. \n",
        "\n",
        "Ваша задача состоит в том, чтобы реализовать разреженный автоэнкодер с KL-лоссом. \n",
        "\n",
        "$$KL(P||Q) =  p(x) \\log \\dfrac {p(x)} {\\hat{p}(x) + \\epsilon} + (1 - p(x)) \\log \\dfrac {(1 - p(x))} {1 - \\hat{p}(x) + \\epsilon} $$\n",
        "Обучите автоэнкодер с требованием, чтобы активировалось не более 10% нейронов. \n",
        "\n",
        "Учтите, что лосс надо считать по активациям, распределенным от 0 до 1 - то есть надо выполнить преобразование, аналогичное тому, что мы делали ранее\n",
        "\n",
        "\n",
        "\n",
        "Напоминаем, что в этом случае мы:\n",
        " 1. Усредняем активации по батчу\n",
        " 2. Для каждого нейрона таким образом получаем среднюю \"вероятность\" активироваться\n",
        " 3. Эта вероятность вряд ли будет в точности равна 0 или 1, но в выражение для KL-loss в знаменатель на всякий случай, добавляем малое число epsilon.\n",
        " 4. Подсчитанный лосс усредняем по всем нейронам слоя\n",
        " 5. Сделайте выводы\n",
        "\n",
        "\n",
        "Постройте графики:\n",
        "\n",
        " 1. Того, как восстанавливает автоэнкодер полученные изображения\n",
        " 2. Средних активаций для каждого класса \n",
        " 3. Распределения силы активаций в целом и средней силы активации каждого нейрона\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pq7a08IVUDMR"
      },
      "source": [
        "В следующих заданиях будет использоваться обычный MNIST"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Of3cCuOUDMR"
      },
      "source": [
        "\n",
        "root = './data'\n",
        "\n",
        "train_set = dset.MNIST(root=root, \n",
        "                       train=True, \n",
        "                       transform=torchvision.transforms.ToTensor(),\n",
        "                       download=True)\n",
        "test_set = dset.MNIST(root=root, \n",
        "                      train=False,\n",
        "                      transform=torchvision.transforms.ToTensor(),\n",
        "                      download=True)\n",
        "\n",
        "test_noise_set = dset.MNIST(root=root, \n",
        "                      train=False,\n",
        "                      transform=torchvision.transforms.Compose([\n",
        "                          torchvision.transforms.ToTensor(),\n",
        "                          AddGaussianNoise(0., 0.30)\n",
        "                      ]),\n",
        "                      download=True)\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    train_set, \n",
        "    batch_size=64,\n",
        "    shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    train_set, \n",
        "    batch_size=64,\n",
        "    shuffle=False)\n",
        "\n",
        "test_noised_dataloader = torch.utils.data.DataLoader(\n",
        "    torch.utils.data.Subset(test_noise_set, list(range(64))),\n",
        "    batch_size=64, \n",
        "    shuffle=False)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PV7tSanzUDMS"
      },
      "source": [
        "def to_01_activation(latent):\n",
        "  activations = (torch.sigmoid(latent.abs()) - 0.5) * 2\n",
        "  return activations\n",
        "\n",
        "def sparse_kl_loss(latent, p=0.10, eps=10e-5):\n",
        "  activations = to_01_activation(latent)\n",
        "  phat = ... \n",
        "  loss = ...\n",
        "  return loss.mean()\n",
        "\n",
        "\n",
        "def sparse_ae_pass_handler(encoder, decoder, data, *args, **kwargs):\n",
        "    latent = encoder(data)\n",
        "    recons = decoder(latent)\n",
        "    return latent, recons\n",
        "\n",
        "def sparse_ae_loss_handler(data, recons, latent, beta=0.1, *args, **kwargs):\n",
        "    return F.binary_cross_entropy(recons, data) + sparse_kl_loss(latent)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nEo4gMrDUDMS"
      },
      "source": [
        "latent_size = 16 * 16\n",
        "\n",
        "learning_rate = 1e-4\n",
        "encoder = Encoder(latent_size=latent_size)\n",
        "decoder = Decoder(latent_size=latent_size)\n",
        "\n",
        "\n",
        "encoder = encoder.to(device)\n",
        "decoder = decoder.to(device)\n",
        "\n",
        "optimizer = optim.Adam(chain(encoder.parameters(),\n",
        "                            decoder.parameters()\n",
        "                           ),\n",
        "                      lr=learning_rate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8I8ucDzAUDMT"
      },
      "source": [
        "# enter your code here\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ix-BLZScUDMT"
      },
      "source": [
        "# Задание 3.1 Сэмплирование из обычного VAE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j6xRx-7wUDMT"
      },
      "source": [
        "\n",
        "\n",
        "В случае с обычным VAE мы визуализировали только центры распределений, соответствувющих цифрам. Хотелось бы получить более полное представление о том, как выглядит латентное пространство. \n",
        "\n",
        "Задача:\n",
        " 1. Обучить VAE из лекции (latent_size = 2)\n",
        " 2. Визуализировать латентные представления, который приходят на вход в decoder. Для этого можно воспользоваться функцией vae_reparametrization, возможно, переписав ее на numpy (один из вариантов)\n",
        " 3. Из каждого распределения, соответствующего объекту надо сэмплировать несколько раз(хотя бы 10). Чтобы точки на полученном графике не полностью перекрывались, используйте параметр alpha из sns.scatterplot или plot_manifold из лекции"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y1oAY83MUDMT"
      },
      "source": [
        "class VAEEncoder(Encoder):\n",
        "    def __init__(self, latent_size):\n",
        "        if latent_size % 2 != 0:\n",
        "            raise Exception(\"Latent size for VAEEncoder must be even\")\n",
        "        super().__init__(latent_size)\n",
        "\n",
        "def vae_split(latent):\n",
        "    size = latent.shape[1] // 2\n",
        "    mu = latent[:, :size]\n",
        "    log_var = latent[:, size:]\n",
        "    return mu, log_var\n",
        "\n",
        "def vae_reparametrize(mu, log_var):\n",
        "    sigma = torch.exp(0.5 * log_var)\n",
        "    z = torch.randn(mu.shape[0],\n",
        "                    mu.shape[1]).cuda()\n",
        "    return z * sigma + mu \n",
        "\n",
        "def vae_pass_handler(encoder, decoder, data, *args, **kwargs):\n",
        "    latent = encoder(data)\n",
        "    mu, log_var = vae_split(latent)\n",
        "    sample = vae_reparametrize(mu, log_var)\n",
        "    recons = decoder(sample)\n",
        "    return latent, recons\n",
        "\n",
        "def kld_loss(mu, log_var):\n",
        "    var = log_var.exp()\n",
        "    kl_loss = torch.mean(-0.5 * torch.sum(1 + log_var - mu ** 2 - var, dim = 1),\n",
        "                          dim = 0)  \n",
        "    return kl_loss\n",
        "\n",
        "def vae_loss_handler(data, recons, latent, kld_weight=0.005, *args, **kwargs):\n",
        "    mu, log_var = vae_split(latent)\n",
        "    kl_loss = kld_loss(mu, log_var)\n",
        "    return kld_weight * kl_loss + F.binary_cross_entropy(recons, data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zz9l7PKJUDMU"
      },
      "source": [
        "# enter your code here\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UWNmafoBUDMU"
      },
      "source": [
        "## Задание 3.2. Визуализация латетного пространства"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CL4xOX5oUDMU"
      },
      "source": [
        "\n",
        "Для модели из предыдущего занятия, можно получить распределение классов цифр на плоскости, типа такого:\n",
        "\n",
        "<img src=\"https://edunet.kea.su/repo/src/L14_Encoders/img/vae_sampling.png\" alt=\"alttext\" style=\"width: 500px;\"/>\n",
        "\n",
        "Вашей задачей будет получить похожее изображение, используя модель из задания выше. Используйте побольше изображений в каждом ряду (скажем, 50). Иначе все цифры можете не увидеть"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rUGOWb8FUDMU"
      },
      "source": [
        "# enter your code here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N51Slhr0UDMU"
      },
      "source": [
        "# Задание 4. Перенос стиля при помощи CVAE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yLy950xgUDMV"
      },
      "source": [
        "\n",
        "\n",
        "Обучите CVAE из лекции (latent_size=2)\n",
        "\n",
        "Посмотрим на результат применения нескольких разных стилей семерки, для других цифр\n",
        "\n",
        "\n",
        "<img src=\"https://edunet.kea.su/repo/src/L14_Encoders/img/style_transfer.png\" alt=\"alttext\" style=\"width: 500px;\"/>. \n",
        "\n",
        "Задача:\n",
        "\n",
        "Реализовать визуализацию стилей тройки, для других цифр\n",
        "\n",
        "Для этого нужно выбрать 10 разных троек, желательно брать случайные 10 троек из датасета(seed зафиксируем)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rlU6wAQOUDMV"
      },
      "source": [
        "# Задание 5. Conditional adversarial autoencoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iAELYKfoUDMV"
      },
      "source": [
        "\n",
        "\n",
        "У нас есть AAE. У нас есть Conditional Autoencoders.\n",
        "\n",
        "Осталось скрестить. Конкретно - теперь будем передавать метку декодеру.\n",
        "\n",
        "Что произойдет, если не передавать метку дискриминатору, но при этом передавать метку декодеру? \n",
        "\n",
        "Правильно, автоэнкодеру может оказаться выгоднее игнорировать метку и \"зарезервировать\" под каждую цифру только часть латентного пространства. \n",
        "Мы так не хотим. Потому необходимо добавить в дискриминатор метку - получим \"условный\" дискриминатор\n",
        "\n",
        "Остается еще один вопрос - что передавать ему в качестве метки, когда мы передаем ему сэмплы из равномерного распределения? \n",
        "\n",
        "Будем просто передавать ему равное число меток разных классов. Можно просто сделать так, что число положительных примеров было кратно 10 (рекомендую), можно выбирать метки случайно. \n",
        "\n",
        "Таким образом, надо:\n",
        "\n",
        "1. Реализовать \"условный\" дискриминатор\n",
        "2. Поменять цикл обучения так, чтобы использовать условный декодер и условный дискриминатор.\n",
        "3. Для обученного автоэнкодера посэмплировать 4 и еще одну любую выбранную вами цифру\n",
        "\n",
        "4. **Допбаллы**: можете проверить, что будет, если использовать обычный дискриминатор. Действительно ли нейросеть каждому объекту начнет сопоставлять лишь часть пространства?\n",
        "\n",
        "Может быть полезным, еще больше увеличить размер батча с реальными изображениями. Для батча размера 128 на 10 классов изображений получится, что на каждой итерации для латентного пространства каждой цифры используется порядка 12 изображений, что не очень много.\n",
        "\n",
        "Равномерное распределение можете взять на отрезке от -1 до 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o1XYG-CFUDMV"
      },
      "source": [
        "def generate_uniform(shape): # U[-1, 1]\n",
        "  return torch.rand( *shape ) * 2 - 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q1aWeKRjUDMV"
      },
      "source": [
        "class CDiscriminator(nn.Module):\n",
        "    def __init__(self, latent_size):\n",
        "        super().__init__()\n",
        "        self.discriminator = nn.Sequential(nn.Linear(latent_size + 10, 512),\n",
        "                                           nn.BatchNorm1d(512),\n",
        "                                           nn.LeakyReLU(0.2),\n",
        "                                           nn.Linear(512, 256),\n",
        "                                           nn.BatchNorm1d(256),\n",
        "                                           nn.LeakyReLU(0.2),\n",
        "                                           nn.Linear(256, 1),\n",
        "                                           nn.Sigmoid())\n",
        "        \n",
        "    def forward(self, x, lab):\n",
        "        x = ...\n",
        "        x = self.discriminator(x)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BWQcdSLeUDMW"
      },
      "source": [
        "# Задание 6. Детекция аномалий с помощью Autoencoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bvli0G6LUDMW"
      },
      "source": [
        "Представим следующую ситуацию, нам нужна система, которая принимает изображение сетчатки глаза, если же изображение не является фотографией сетчатки глаза, то нам нужно сообщить пользователю об ошибке и не принимать это изображение.\n",
        "\n",
        "Идея заключается в следующем: если автоэнкодер может выучить внутреннее представление данных,например фотографий сетчатки глаза, то при восстановлении данных, которые не являются фотографией сетчатки глаза, ошибка будет существенно больше. Установив порог этой ошибки мы сможем отделять нужные фотографии от не нужных.\n",
        "\n",
        "\n",
        "\n",
        "*   Обучите автоэнкодер на фотографиях сетчатки глаза(RetinaMNIST)\n",
        "*   Подайте в автоэнкодер другое изображение(можно взять BloodMNIST)\n",
        "*   Посчитайте ошибку восстановления для разных датасетов\n",
        "*   Установите порог(значение ошибки) для определения класса фотографии(сетчатка глаза или нет)\n",
        "*   Проведите тесты \n",
        "*   Напишите выводы\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "socTlQrmUDMW"
      },
      "source": [
        "from IPython.display import clear_output\n",
        "!pip install --upgrade git+https://github.com/MedMNIST/MedMNIST.git\n",
        "clear_output()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hA4-J-ZjUDMW"
      },
      "source": [
        "import medmnist\n",
        "from medmnist import INFO, Evaluator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_nK1PCPUDMW"
      },
      "source": [
        "data_flag = 'retinamnist'\n",
        "info = INFO[data_flag]\n",
        "\n",
        "DataClass = getattr(medmnist, info['python_class'])\n",
        "\n",
        "# preprocessing\n",
        "data_transform = transforms.Compose([transforms.Grayscale(num_output_channels=1),transforms.ToTensor()])\n",
        "\n",
        "# load the data\n",
        "train_dataset = DataClass(split='train', transform=data_transform, download=True)\n",
        "test_dataset = DataClass(split='test', transform=data_transform, download=True)\n",
        "\n",
        "# encapsulate data into dataloader form\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=128, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=1, shuffle=False)\n",
        "\n",
        "# load the data\n",
        "data_flag = 'bloodmnist'\n",
        "info = INFO[data_flag]\n",
        "DataClass = getattr(medmnist, info['python_class'])\n",
        "\n",
        "test_dataset_1 = DataClass(split='test', transform=data_transform, download=True)\n",
        "test_loader_1 = torch.utils.data.DataLoader(dataset=test_dataset_1, batch_size=1, shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QhZNfSkaUDMX"
      },
      "source": [
        "# enter your code here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mIMjuIXGUDMX"
      },
      "source": [
        "# Задание 7. AAE и латентное пространство"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fzens6NMUDMX"
      },
      "source": [
        "\n",
        "\n",
        "На самом деле, идея с равномерными распределением не очень хороша - мы строго отделили их друг от друга, что принуждает наш автоэнкодер либо разбивать даже похожие цифры, если они относятся к разным классам, либо игнорировать дискриминатор и получать за это штраф.\n",
        "\n",
        "Приятнее в данном случае использовать распределения, которые определены на области от плюс до минус бесконечности. \n",
        "\n",
        "Расположить их на таком расстоянии, чтобы в принципе они пересекались, но очень редко. Для этой цели нам подойдут нормальные распределения.\n",
        "\n",
        "Сделаем сетку только из 9 нормальных распределений - все равно мы уже не раз наблюдали, что 4 и 9 очень трудно отличимы, потому кластеров у нас максимально 9"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uXJlUjx3UDMX"
      },
      "source": [
        "def generate_on_grid(size_for_bound, grid, generator):\n",
        "    samples = []\n",
        "    for boundaries in grid:\n",
        "        s = generator(size_for_bound, *boundaries)\n",
        "        samples.append(s)\n",
        "    sample = torch.cat(samples, dim=0)\n",
        "    return sample\n",
        "\n",
        "def generator_normal(size, xmin, xmax, ymin, ymax):\n",
        "    mean_x = (xmin + xmax) / 2\n",
        "    mean_y = (ymin + ymax) / 2\n",
        "    std_x = (xmax - mean_x) / 2.5\n",
        "    std_y = (ymax - mean_y) / 2.5\n",
        "    x = torch.FloatTensor(size, 1).normal_(mean_x, std_x)\n",
        "    y = torch.FloatTensor(size, 1).normal_(mean_y, std_y)\n",
        "    return torch.cat([x, y], dim=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MsDKc_IMUDMX"
      },
      "source": [
        "from itertools import product\n",
        "grids = [ (x1, x2, x3, x4) for (x1, x2), (x3, x4) in  product([[-1.5, -0.5], [-0.5, 0.5], [0.5, 1.5]], \n",
        "                                                           [[-1.5, -0.5], [-0.5, 0.5], [0.5, 1.5]])]\n",
        "#grids.append((-0.5, 0.5, -2.5, -1.5))\n",
        "plot_manifold(generate_on_grid(516, grids, generator_normal).numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pjR7ObaPUDMY"
      },
      "source": [
        "Обучите AAE переводить изображения в приведенное латентное пространство. Учтите, что может потребоваться много эпох для достижения приемлемого результата.\n",
        "\n",
        "Возможно, для того, чтобы добиться сходимости модели, надо поиграть с числом реальных объектов, которые подаются нейросети на вход "
      ]
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EX14_Encoders.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  }
}