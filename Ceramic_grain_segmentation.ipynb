{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Le0xhaLHRyyS",
    "tags": []
   },
   "source": [
    "# Ceramic Microstructure Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cjFFcbyxRyyU",
    "tags": []
   },
   "source": [
    "## Python packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "import random\n",
    "import numpy as np\n",
    "import time\n",
    "import numba\n",
    "from skimage import morphology\n",
    "from skimage.color import label2rgb\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms\n",
    "from torchvision.transforms import ToTensor, Compose, ToTensor, Normalize, Grayscale, RandomRotation, Resize, RandomGrayscale\n",
    "import os\n",
    "from PIL import Image\n",
    "import torch.optim as optim\n",
    "from itertools import product\n",
    "from torchvision.utils import make_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NkDyHgJeRyyV",
    "tags": []
   },
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5tbjs7QmRyyV",
    "outputId": "39aee152-dd1a-470d-8507-86c09127ba0e"
   },
   "outputs": [],
   "source": [
    "f=h5py.File(\"/Users/nikolai/Desktop/pure_iron_grain_data_sets.hdf5\", \"r\")\n",
    "images = f['image']\n",
    "images=np.moveaxis(images,2,0)\n",
    "labels = f['label']\n",
    "labels=np.moveaxis(labels,2,0)\n",
    "boundaries = f['boundary']\n",
    "boundaries=np.moveaxis(boundaries,2,0)\n",
    "print(images.shape,labels.shape,boundaries.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qc2vEkrGRyyW"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 20))\n",
    "plt.subplot(131)\n",
    "plt.imshow(images[0],cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.title(\"SEM\", fontsize=20)\n",
    "plt.subplot(132)\n",
    "plt.imshow(boundaries[0],cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.title(\"detected boundaries\", fontsize=20)\n",
    "plt.subplot(133)\n",
    "plt.imshow(labels[0],cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.title(\"different grains (labels)\", fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YnssjyA_RyyX"
   },
   "outputs": [],
   "source": [
    "plt.imshow(images[0],cmap='gray')\n",
    "#[plt.imsave(f'Im_Iron/Im_{i}.jpeg', images[i],cmap='gray') for i in range(len(images))]\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iRKux487RyyX",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Cutting source pictures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KvFzExikRyyX"
   },
   "outputs": [],
   "source": [
    "def crop(img: Tuple[float, float], image_size: int) -> Tuple[float, float, float]:\n",
    "    \"\"\"Crop images by certain size\"\"\"\n",
    "    \n",
    "    k: int = 0  # counter\n",
    "    w, h = img.shape  # weight and height of original image\n",
    "    NO_CELLS: int = int(w / image_size)  # number of images in line of original image\n",
    "    images_matrix = np.zeros((int(h / image_size)* int(w / image_size),\n",
    "                              image_size, image_size))  # empty matrix for new images\n",
    "    grid = product(range(0, h, image_size), range(0, w, image_size)) # grid to extract new images\n",
    "    for i, j in grid:\n",
    "        images_matrix[k] = img[j: j + image_size, i: i + image_size]\n",
    "        k += 1\n",
    "    return images_matrix\n",
    "\n",
    "image_size = 128\n",
    "for i, image in enumerate(images):\n",
    "    if i == 0:\n",
    "        croped_images = crop(image, image_size)\n",
    "    else:\n",
    "        croped_images = np.concatenate((croped_images, crop(image, image_size)))\n",
    "\n",
    "print(croped_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WUN7Un0eRyyY"
   },
   "outputs": [],
   "source": [
    "plt.imshow(croped_images[7577],cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DV6cnA31RyyY"
   },
   "outputs": [],
   "source": [
    "class SEM_Dataset(Dataset):\n",
    "    def __init__(self, images):#, labels, boundaries):\n",
    "        self.images = [torch.Tensor(i) for i in croped_images]\n",
    "        #self.boundaries = [torch.Tensor(i) for i in boundaries]\n",
    "        #self.labels = [torch.Tensor(i) for i in labels]\n",
    "        #self.transform = Compose([RandomRotation(degrees=(-179, 179)),\n",
    "        #                          Grayscale(num_output_channels=1)\n",
    "        #                         ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image=self.images[idx]\n",
    "        image=image.reshape(-1,image.shape[0],image.shape[1])\n",
    "        #image=self.transform(image)\n",
    "        #boundary=self.boundaries[idx]\n",
    "        #label=self.labels[idx]\n",
    "        return image#, boundary, label\n",
    "    \n",
    "SEM_images = SEM_Dataset(images)#, boundaries, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## GAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lYBuwYIURyyY",
    "tags": []
   },
   "source": [
    "#### Generator and Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-nEGBNI7RyyY"
   },
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, z_dim=10, im_chan=1, hidden_dim=64):\n",
    "        super(Generator, self).__init__()\n",
    "        self.z_dim = z_dim\n",
    "        self.gen = nn.Sequential(\n",
    "            self.make_gen_block(z_dim, hidden_dim * 4, kernel_size = 8),  # [8, 10, 1, 1] -> [8, 1, 8, 8]\n",
    "            self.make_gen_block(hidden_dim * 4, hidden_dim * 2),  # [8, 1, 8, 8] -> [8, 1, 16, 16]\n",
    "            self.make_gen_block(hidden_dim * 2, hidden_dim),  # [8, 1, 16, 16] -> [8, 1, 32, 32]\n",
    "            self.make_gen_block(hidden_dim, im_chan),  # [8, 1, 32, 32] -> [8, 1, 64, 64]\n",
    "            self.make_gen_block(im_chan, im_chan, final_layer=True),  # [8, 1, 64, 64] -> [8, 1, 128, 128]\n",
    "        )\n",
    "\n",
    "    def make_gen_block(self, input_channels, output_channels, kernel_size=2, stride=2, final_layer=False):\n",
    "        if not final_layer:\n",
    "            return nn.Sequential(\n",
    "                nn.ConvTranspose2d(in_channels=input_channels,\n",
    "                                   out_channels=output_channels,\n",
    "                                   kernel_size=kernel_size,\n",
    "                                   stride=stride,\n",
    "                                   padding=0),\n",
    "                nn.BatchNorm2d(num_features=output_channels),\n",
    "                nn.ReLU()\n",
    "            )\n",
    "        else: # Final Layer\n",
    "            return nn.Sequential(\n",
    "                nn.ConvTranspose2d(in_channels=input_channels,\n",
    "                                   out_channels=output_channels,\n",
    "                                   kernel_size=kernel_size,\n",
    "                                   stride=stride,\n",
    "                                   padding=0),\n",
    "                nn.Tanh()\n",
    "            )\n",
    "            \n",
    "    def unsqueeze_noise(self, noise):\n",
    "        return noise.view(len(noise), self.z_dim, 1, 1)\n",
    "\n",
    "    def forward(self, noise):\n",
    "        x = self.unsqueeze_noise(noise)\n",
    "        return self.gen(x)\n",
    "\n",
    "def get_noise(n_samples, z_dim, device='cpu'):\n",
    "    return torch.randn(n_samples, z_dim, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_gen_block(input_channels, output_channels, kernel_size=2, stride=2, final_layer=False):\n",
    "        if not final_layer:\n",
    "            return nn.Sequential(\n",
    "                nn.ConvTranspose2d(in_channels=input_channels,\n",
    "                                   out_channels=output_channels,\n",
    "                                   kernel_size=kernel_size,\n",
    "                                   stride=stride,\n",
    "                                   padding=0),\n",
    "                nn.BatchNorm2d(num_features=output_channels),\n",
    "                nn.ReLU()\n",
    "            )\n",
    "        else: # Final Layer\n",
    "            return nn.Sequential(\n",
    "                nn.ConvTranspose2d(in_channels=input_channels,\n",
    "                                   out_channels=output_channels,\n",
    "                                   kernel_size=kernel_size,\n",
    "                                   stride=stride,\n",
    "                                   padding=0),\n",
    "                nn.Tanh()\n",
    "            )\n",
    "            \n",
    "def unsqueeze_noise(noise):\n",
    "    return noise.view(len(noise), z_dim, 1, 1)\n",
    "z_dim = 10\n",
    "gen = nn.Sequential(\n",
    "            make_gen_block(z_dim, hidden_dim * 4, kernel_size = 4),  # [8, 10, 1, 1] -> [8, 1, 8, 8]\n",
    "            make_gen_block(hidden_dim * 8, hidden_dim * 4),  # [8, 1, 8, 8] -> [8, 1, 16, 16]\n",
    "            make_gen_block(hidden_dim * 4, hidden_dim*2),  # [8, 1, 16, 16] -> [8, 1, 32, 32]\n",
    "            make_gen_block(hidden_dim * 2, im_chan, final_layer=False),  # [8, 1, 32, 32] -> [8, 1, 64, 64]\n",
    "            make_gen_block(hidden_dim, im_chan, final_layer=True),  # [8, 1, 64, 64] -> [8, 1, 128, 128]\n",
    "        )\n",
    "block1 = nn.Sequential(make_gen_block(z_dim, hidden_dim * 4, kernel_size = 8))  # [8, 10, 1, 1] -> [8, 1, 8, 8]\n",
    "block2 = nn.Sequential(make_gen_block(hidden_dim * 4, hidden_dim * 2))  # [8, 1, 8, 8] -> [8, 1, 16, 16]\n",
    "block3 = nn.Sequential(make_gen_block(hidden_dim * 2, hidden_dim))  # [8, 1, 16, 16] -> [8, 1, 32, 32]\n",
    "block4 = nn.Sequential(make_gen_block(hidden_dim , im_chan, final_layer=False))  # [8, 1, 32, 32] -> [8, 1, 64, 64]\n",
    "block5 = nn.Sequential(make_gen_block(im_chan, im_chan, final_layer=True))  # [8, 1, 64, 64] -> [8, 1, 128, 128]\n",
    "n_samples=8\n",
    "noise = get_noise(n_samples, z_dim)\n",
    "noise = unsqueeze_noise(noise)\n",
    "\n",
    "im = block1(noise)\n",
    "print(im.shape)\n",
    "im = block2(im)\n",
    "print(im.shape)\n",
    "im = block3(im)\n",
    "print(im.shape)\n",
    "im = block4(im)\n",
    "print(im.shape)\n",
    "im = block5(im)\n",
    "print(im.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ds_uSDNsRyyZ"
   },
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, im_chan=1, hidden_dim=30):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.disc = nn.Sequential(\n",
    "            self.make_disc_block(im_chan, hidden_dim),  # [8, 1, 128, 128] -> [8, 16, 64, 64]\n",
    "            self.make_disc_block(hidden_dim, hidden_dim * 2, final_layer=False),  # [8, 16, 64, 64] -> [8, 32, 32, 32]\n",
    "            self.make_disc_block(hidden_dim * 2, hidden_dim * 4, final_layer=False),  # [8, 60, 32, 32] -> [8, 120, 16, 16]\n",
    "            self.make_disc_block(hidden_dim * 4, hidden_dim * 8, final_layer=False),  # [8, 120, 16, 16] -> [8, 240, 8, 8]\n",
    "            self.make_disc_block(hidden_dim * 8, hidden_dim * 16, final_layer=False),  # [8, 240, 8, 8] -> [8, 480, 4, 4]\n",
    "            self.make_disc_block(hidden_dim * 16, hidden_dim * 32, final_layer=True)  # [8, 480, 4, 4] -> [8, 960, 2, 2]\n",
    "        \n",
    "        )\n",
    "        self.lin = torch.nn.Linear(3840, 1)  # [8, 3840] -> [8, 1]\n",
    "        self.sig = nn.Sigmoid()\n",
    "        \n",
    "    def make_disc_block(self, input_channels, output_channels, kernel_size=3, stride=1, final_layer=False):\n",
    "        if not final_layer:\n",
    "            return nn.Sequential(\n",
    "                nn.Conv2d(in_channels=input_channels,\n",
    "                          out_channels=output_channels,\n",
    "                          kernel_size=kernel_size,\n",
    "                          stride=stride),\n",
    "                nn.BatchNorm2d(output_channels),\n",
    "                nn.MaxPool2d(kernel_size=2, stride=2, padding=1),\n",
    "                nn.Dropout(p=0.2),\n",
    "                nn.LeakyReLU(0.2)\n",
    "            )\n",
    "        else: # Final Layer\n",
    "            return nn.Sequential(\n",
    "                nn.Conv2d(in_channels=input_channels,\n",
    "                          out_channels=output_channels,\n",
    "                          kernel_size=kernel_size,\n",
    "                          stride=stride)\n",
    "            )\n",
    "\n",
    "    def forward(self, image):\n",
    "        disc_pred = self.disc(image)\n",
    "        disc_pred = disc_pred.view(len(disc_pred), -1)  # [8, 960, 2, 2] -> [8, 3840]\n",
    "        disc_pred = self.lin(disc_pred)\n",
    "        return self.sig(disc_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_disc_block(input_channels, output_channels, kernel_size=3, stride=1, final_layer=False):\n",
    "        if not final_layer:\n",
    "            return nn.Sequential(\n",
    "                nn.Conv2d(in_channels=input_channels,\n",
    "                          out_channels=output_channels,\n",
    "                          kernel_size=kernel_size,\n",
    "                          stride=stride),\n",
    "                nn.BatchNorm2d(output_channels),\n",
    "                nn.MaxPool2d(kernel_size=2, stride=2, padding=1),\n",
    "                nn.Dropout(p=0.2),\n",
    "                nn.LeakyReLU(0.2)\n",
    "            )\n",
    "        else: # Final Layer\n",
    "            return nn.Sequential(\n",
    "                nn.Conv2d(in_channels=input_channels,\n",
    "                          out_channels=output_channels,\n",
    "                          kernel_size=kernel_size,\n",
    "                          stride=stride)\n",
    "            )\n",
    "\n",
    "im_chan=1\n",
    "hidden_dim=30\n",
    "\n",
    "disc = nn.Sequential(\n",
    "            make_disc_block(im_chan, hidden_dim),\n",
    "            make_disc_block(hidden_dim, hidden_dim * 2, final_layer=True),\n",
    "            #make_disc_block(hidden_dim * 2, 1, final_layer=True),\n",
    "            )\n",
    "lin = torch.nn.Linear(3840, 1)\n",
    "sig = nn.Sigmoid()\n",
    "\n",
    "\n",
    "\n",
    "fake = torch.randn(8, 1, 128, 128)\n",
    "block1 = make_disc_block(im_chan, hidden_dim)  # [8, 1, 128, 128] -> [8, 30, 64, 64]\n",
    "fake = block1(fake)\n",
    "print(fake.shape)\n",
    "block2 = make_disc_block(hidden_dim, hidden_dim * 2, final_layer=False)  # [8, 30, 64, 64] -> [8, 60, 32, 32]\n",
    "fake = block2(fake)\n",
    "print(fake.shape)\n",
    "block3 = make_disc_block(hidden_dim * 2, hidden_dim * 4, final_layer=False)  # [8, 60, 32, 32] -> [8, 120, 16, 16]\n",
    "fake = block3(fake)\n",
    "print(fake.shape)\n",
    "block4 = make_disc_block(hidden_dim * 4, hidden_dim * 8, final_layer=False)  # [8, 120, 16, 16] -> [8, 240, 8, 8]\n",
    "fake = block4(fake)\n",
    "print(fake.shape)\n",
    "block5 = make_disc_block(hidden_dim * 8, hidden_dim * 16, final_layer=False)  # [8, 240, 8, 8] -> [8, 480, 4, 4]\n",
    "fake = block5(fake)\n",
    "print(fake.shape)\n",
    "block6 = make_disc_block(hidden_dim * 16, hidden_dim * 32, final_layer=True)  # [8, 480, 4, 4] -> [8, 960, 2, 2]\n",
    "fake = block6(fake)\n",
    "print(fake.shape)\n",
    "fake = torch.flatten(fake, start_dim = 1)  # [batch, 960, 2, 2] -> [batch, 3840]\n",
    "print(fake.shape)\n",
    "fake = lin(fake)  # [8, 3840] -> [8, 1]\n",
    "print(fake.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import MNIST\n",
    "from torchvision import transforms\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,)),\n",
    "])\n",
    "dataloader = DataLoader(\n",
    "    MNIST('.', download=True, transform=transform),\n",
    "    batch_size=8,\n",
    "    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, real in enumerate(dataloader):\n",
    "    print(real[0].shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### DCGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_dim = 20\n",
    "display_step = 500\n",
    "batch_size=8\n",
    "\n",
    "train_loader=DataLoader(dataset=SEM_images, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "lr = 0.001\n",
    "beta_1 = 0.5 \n",
    "beta_2 = 0.999\n",
    "\n",
    "device = 'cpu'\n",
    "\n",
    "gen = Generator(z_dim).to(device)\n",
    "gen_opt = torch.optim.Adam(gen.parameters(), lr=lr, betas=(beta_1, beta_2))\n",
    "disc = Discriminator().to(device) \n",
    "disc_opt = torch.optim.Adam(disc.parameters(), lr=lr, betas=(beta_1, beta_2))\n",
    "\n",
    "# initialize the weights to the normal distribution\n",
    "# with mean 0 and standard deviation 0.02\n",
    "def weights_init(m):\n",
    "    if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\n",
    "        torch.nn.init.normal_(m.weight, 0, 0.02)\n",
    "    if isinstance(m, nn.BatchNorm2d):\n",
    "        torch.nn.init.normal_(m.weight, 0, 0.02)\n",
    "        torch.nn.init.constant_(m.bias, 1)\n",
    "gen = gen.apply(weights_init)\n",
    "disc = disc.apply(weights_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3c4UleAhRyya",
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_epochs = 10\n",
    "cur_step = 0\n",
    "mean_generator_loss = 0\n",
    "mean_discriminator_loss = 0\n",
    "\n",
    "t0 = time.time()\n",
    "\n",
    "gen_loss_list = []\n",
    "disc_loss_list = []\n",
    "for epoch in range(n_epochs):\n",
    "    # Dataloader returns the batches\n",
    "    for i, real in enumerate(train_loader):\n",
    "        #real=real[0]\n",
    "\n",
    "        ## Update discriminator ##\n",
    "        \n",
    "        fake_noise = get_noise(batch_size, z_dim)\n",
    "        fake = gen(fake_noise)\n",
    "        disc_fake_pred = disc(fake)#.detach())\n",
    "        disc_fake_loss = criterion(disc_fake_pred, torch.zeros_like(disc_fake_pred))\n",
    "        disc_real_pred = disc(real)\n",
    "        print(disc_real_pred)\n",
    "        disc_real_loss = criterion(disc_real_pred, torch.ones_like(disc_real_pred))\n",
    "        disc_loss = (disc_fake_loss + disc_real_loss) / 2\n",
    "\n",
    "        # Keep track of the average discriminator loss\n",
    "        mean_discriminator_loss += disc_loss.item() / display_step\n",
    "        # Update gradients\n",
    "        disc_loss.backward(retain_graph=True)\n",
    "        # Update optimizer\n",
    "        disc_opt.step()\n",
    "        disc_opt.zero_grad()\n",
    "\n",
    "        ## Update generator ##\n",
    "        \n",
    "        #fake_noise = get_noise(batch_size, z_dim)\n",
    "        #fake = gen(fake_noise)\n",
    "        disc_fake_pred = disc(fake)\n",
    "        gen_loss = criterion(disc_fake_pred, torch.ones_like(disc_fake_pred))\n",
    "        gen_loss.backward()\n",
    "        gen_opt.step()\n",
    "        gen_opt.zero_grad()\n",
    "\n",
    "        # Keep track of the average generator loss\n",
    "        mean_generator_loss += gen_loss.item() / display_step\n",
    "\n",
    "        ## Visualization code ##\n",
    "        t1 = (time.time() - t0) / 60\n",
    "        if cur_step % display_step == 0 and cur_step > 0:\n",
    "            print(f\"Epoch {epoch}, step {cur_step}: \"+ \n",
    "                  f\"Generator loss: {mean_generator_loss}, \"+ \n",
    "                  f\"discriminator loss: {mean_discriminator_loss}, \"+\n",
    "                  f\"time: {t1} min\")\n",
    "            fix, axs = plt.subplots(ncols=2)\n",
    "            axs[0].imshow(fake[0][0].detach().numpy(),cmap='gray')\n",
    "            axs[0].set(xticklabels=[], yticklabels=[], xticks=[], yticks=[])\n",
    "            axs[1].imshow(real[0][0].detach().numpy(),cmap='gray')\n",
    "            axs[1].set(xticklabels=[], yticklabels=[], xticks=[], yticks=[])\n",
    "            plt.show()\n",
    "            gen_loss_list.append(mean_generator_loss)\n",
    "            disc_loss_list.append(mean_discriminator_loss)\n",
    "            mean_generator_loss = 0\n",
    "            mean_discriminator_loss = 0\n",
    "        cur_step += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(gen.state_dict(), \"./gen_weights.pth\")\n",
    "torch.save(disc.state_dict(), \"./disc_weights.pth\")\n",
    "gen.load_state_dict(torch.load(\"./gen_weights.pth\"))\n",
    "disc.load_state_dict(torch.load(\"./disc_weights.pth\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### WGAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Wasserstein Losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gradient(disc, real, fake, epsilon):\n",
    "    '''\n",
    "    Return the gradient of the discriminator's scores with respect to mixes of real and fake images.\n",
    "    Parameters:\n",
    "        disc: the discriminator model\n",
    "        real: a batch of real images\n",
    "        fake: a batch of fake images\n",
    "        epsilon: a vector of the uniformly random proportions of real/fake per mixed image\n",
    "    Returns:\n",
    "        gradient: the gradient of the discriminator's scores, with respect to the mixed image\n",
    "    '''\n",
    "    mixed_images = real * epsilon + fake * (1 - epsilon)  # Mix the images together\n",
    "    mixed_scores = disc(mixed_images)  # Calculate the discriminator's scores on the mixed images\n",
    "    \n",
    "    # Take the gradient of the scores with respect to the images\n",
    "    gradient = torch.autograd.grad(\n",
    "        inputs=mixed_images,\n",
    "        outputs=mixed_scores,\n",
    "        grad_outputs=torch.ones_like(mixed_scores), \n",
    "        create_graph=True,\n",
    "        retain_graph=True,\n",
    "    )[0]\n",
    "    return gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_penalty(gradient):\n",
    "    '''\n",
    "    Return the gradient penalty, given a gradient.\n",
    "    Given a batch of image gradients, you calculate the magnitude of each image's gradient\n",
    "    and penalize the mean quadratic distance of each magnitude to 1.\n",
    "    Parameters:\n",
    "        gradient: the gradient of the critic's scores, with respect to the mixed image\n",
    "    Returns:\n",
    "        penalty: the gradient penalty\n",
    "    '''\n",
    "    gradient = gradient.view(len(gradient), -1)  # Flatten the gradients so that each row captures one image\n",
    "    gradient_norm = gradient.norm(2, dim=1)  # Calculate the magnitude of every row\n",
    "    # Penalize the mean squared distance of the gradient norms from 1\n",
    "    penalty = ((gradient_norm-1)**2).mean()\n",
    "    return penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gen_loss(disc_fake_pred):\n",
    "    '''\n",
    "    Return the loss of a generator given the critic's scores of the generator's fake images.\n",
    "    Parameters:\n",
    "        crit_fake_pred: the critic's scores of the fake images\n",
    "    Returns:\n",
    "        gen_loss: a scalar loss value for the current batch of the generator\n",
    "    '''\n",
    "    gen_loss = -disc_fake_pred.mean()\n",
    "    return gen_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_disc_loss(disc_fake_pred, disc_real_pred, gp, c_lambda):\n",
    "    '''\n",
    "    Return the loss of a critic given the critic's scores for fake and real images,\n",
    "    the gradient penalty, and gradient penalty weight.\n",
    "    Parameters:\n",
    "        crit_fake_pred: the critic's scores of the fake images\n",
    "        crit_real_pred: the critic's scores of the real images\n",
    "        gp: the unweighted gradient penalty\n",
    "        c_lambda: the current weight of the gradient penalty \n",
    "    Returns:\n",
    "        crit_loss: a scalar for the critic's loss, accounting for the relevant factors\n",
    "    '''\n",
    "    disc_loss = (disc_fake_pred-disc_real_pred+c_lambda*gp).mean()\n",
    "    return disc_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Traning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CvuTulOFRyyZ"
   },
   "outputs": [],
   "source": [
    "z_dim = 10\n",
    "display_step = 500\n",
    "lr = 0.0001\n",
    "\n",
    "beta_1 = 0.5 \n",
    "beta_2 = 0.999\n",
    "#device = 'cuda'\n",
    "\n",
    "batch_size=8\n",
    "train_loader=DataLoader(dataset=SEM_images, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-ruzDoSxRyyZ"
   },
   "outputs": [],
   "source": [
    "gen = Generator(z_dim)#.to(device)\n",
    "gen_opt = torch.optim.Adam(gen.parameters(), lr=lr, betas=(beta_1, beta_2))\n",
    "disc = Discriminator()#.to(device) \n",
    "disc_opt = torch.optim.Adam(disc.parameters(), lr=lr, betas=(beta_1, beta_2))\n",
    "\n",
    "# initialize the weights to the normal distribution\n",
    "# with mean 0 and standard deviation 0.02\n",
    "def weights_init(m):\n",
    "    if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\n",
    "        torch.nn.init.normal_(m.weight, 0, 0.02)\n",
    "    if isinstance(m, nn.BatchNorm2d):\n",
    "        torch.nn.init.normal_(m.weight, 0, 0.02)\n",
    "        torch.nn.init.constant_(m.bias, 1)\n",
    "gen = gen.apply(weights_init)\n",
    "disc = disc.apply(weights_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 10\n",
    "cur_step = 0\n",
    "mean_generator_loss = 0\n",
    "mean_discriminator_loss = 0\n",
    "disc_repeats = 5\n",
    "c_lambda = 10\n",
    "gen_loss_list = []\n",
    "disc_loss_list = []\n",
    "device = 'cpu'\n",
    "for epoch in range(n_epochs):\n",
    "    # Dataloader returns the batches\n",
    "    for i, real in enumerate(train_loader):\n",
    "        cur_batch_size = len(real)\n",
    "        \n",
    "        mean_iteration_disc_loss = 0\n",
    "        for _ in range(disc_repeats):\n",
    "            ### Update discriminator ###\n",
    "            disc_opt.zero_grad()\n",
    "            fake_noise = get_noise(batch_size, z_dim, device=device)\n",
    "            fake = gen(fake_noise)\n",
    "            disc_fake_pred = disc(fake.detach())\n",
    "            disc_real_pred = disc(real)\n",
    "\n",
    "            epsilon = torch.rand(len(real), 1, 1, 1, device=device, requires_grad=True)\n",
    "            gradient = get_gradient(disc, real, fake.detach(), epsilon)\n",
    "            gp = gradient_penalty(gradient)\n",
    "            disc_loss = get_disc_loss(disc_fake_pred, disc_real_pred, gp, c_lambda)\n",
    "\n",
    "            # Keep track of the average critic loss in this batch\n",
    "            mean_iteration_disc_loss += disc_loss.item() / disc_repeats\n",
    "            # Update gradients\n",
    "            disc_loss.backward(retain_graph=True)\n",
    "            # Update optimizer\n",
    "            disc_opt.step()\n",
    "        #disc_loss += [mean_iteration_disc_loss]\n",
    "        mean_discriminator_loss += disc_loss.item() / display_step\n",
    "\n",
    "        ## Update generator ##\n",
    "        gen_opt.zero_grad()\n",
    "        fake_noise_2 = get_noise(cur_batch_size, z_dim)#, device=device)\n",
    "        fake_2 = gen(fake_noise_2)\n",
    "        disc_fake_pred = disc(fake_2)\n",
    "        gen_loss = criterion(disc_fake_pred, torch.ones_like(disc_fake_pred))\n",
    "        gen_loss.backward()\n",
    "        gen_opt.step()\n",
    "\n",
    "        # Keep track of the average generator loss\n",
    "        mean_generator_loss += gen_loss.item() / display_step\n",
    "\n",
    "        ## Visualization code ##\n",
    "        if cur_step % display_step == 0 and cur_step > 0:\n",
    "            print(f\"Epoch {epoch}, step {cur_step}:\"+ \n",
    "                  f\"Generator loss: {mean_generator_loss}, discriminator loss: {mean_discriminator_loss}\")\n",
    "            fix, axs = plt.subplots(ncols=2)\n",
    "            axs[0].imshow(fake[0][0].detach().numpy(),cmap='gray')\n",
    "            axs[0].set(xticklabels=[], yticklabels=[], xticks=[], yticks=[])\n",
    "            axs[1].imshow(real[0][0].detach().numpy(),cmap='gray')\n",
    "            axs[1].set(xticklabels=[], yticklabels=[], xticks=[], yticks=[])\n",
    "            plt.show()\n",
    "            gen_loss_list.append(mean_generator_loss)\n",
    "            disc_loss_list.append(mean_discriminator_loss)\n",
    "            mean_generator_loss = 0\n",
    "            mean_discriminator_loss = 0\n",
    "        cur_step += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Image Segmantation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HSzLKvaDRyya",
    "tags": []
   },
   "source": [
    "### W-Net block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mOorM8R3Ryya"
   },
   "outputs": [],
   "source": [
    "class W_Net(nn.Module):\n",
    "    def __init__(self, input_channels = 1):\n",
    "        super().__init__()\n",
    "        \n",
    "        #1st floor: channels: 1 -> 64 -> 64\n",
    "        self.floor_1 = nn.Sequential(self.simple_conv2d_block(input_channels, input_channels*64),\n",
    "                                     self.simple_conv2d_block(input_channels*64, input_channels*64))\n",
    "        #1st donwscale: im_size: 64 -> 32\n",
    "        self.downscale_1 = nn.Sequential(self.simple_maxpool_block(kernel_size = 2, stride = 2))\n",
    "        #2nd floor: channels: 64 -> 128 -> 128\n",
    "        self.floor_2 = nn.Sequential(self.simple_conv2d_block(input_channels*64, input_channels*128),\n",
    "                                     self.simple_conv2d_block(input_channels*128, input_channels*128))\n",
    "        #2nd donwscale: im_size: 32 -> 16\n",
    "        self.downscale_2 = nn.Sequential(self.simple_maxpool_block(kernel_size = 2, stride = 2))\n",
    "        #3d floor: channels: 128 -> 256 -> 256\n",
    "        self.floor_3 = nn.Sequential(self.simple_conv2d_block(input_channels*128, input_channels*256),\n",
    "                                     self.simple_conv2d_block(input_channels*256, input_channels*256))\n",
    "        #2nd upscale: im_size: 16 -> 32; channels: 256 -> 128\n",
    "        self.upscale_2 = nn.Sequential(self.simple_convtranspose2d_block(input_channels*256, input_channels*128))\n",
    "        #2nd floor: channels: 256 -> 128 -> 128\n",
    "        self.floor_2_up = nn.Sequential(self.simple_conv2d_block(input_channels*256, input_channels*128),\n",
    "                                     self.simple_conv2d_block(input_channels*128, input_channels*128))\n",
    "        #1st upscale: im_size: 32 -> 64; channels: 128 -> 64\n",
    "        self.upscale_1 = nn.Sequential(self.simple_convtranspose2d_block(input_channels*128, input_channels*64))\n",
    "        #1st floor: channels: 128 -> 64 -> 1\n",
    "        self.floor_1_up = nn.Sequential(self.simple_conv2d_block(input_channels*128, input_channels*64),\n",
    "                                     self.simple_conv2d_block(input_channels*64, input_channels))\n",
    "\n",
    "    def simple_conv2d_block(self, input_channels, output_channels, kernel_size=3, padding = 1):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_channels=input_channels,\n",
    "                      out_channels=output_channels,\n",
    "                      kernel_size=kernel_size,\n",
    "                      padding = 1),\n",
    "            nn.BatchNorm2d(output_channels),\n",
    "            nn.LeakyReLU(0.2))\n",
    "            \n",
    "    def simple_maxpool_block(self, kernel_size = 2, stride = 2):\n",
    "        return nn.MaxPool2d(kernel_size, stride)\n",
    "    \n",
    "    def simple_convtranspose2d_block(self, input_channels, output_channels, kernel_size=2,\n",
    "                                     stride = 2, padding = 1):\n",
    "        return nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels = input_channels,\n",
    "                               out_channels = output_channels,\n",
    "                               kernel_size = kernel_size, \n",
    "                               stride = stride),\n",
    "                               #padding = padding),\n",
    "            nn.BatchNorm2d(int(input_channels/2)),\n",
    "            nn.LeakyReLU(0.2))\n",
    "        \n",
    "    def concat(self, tensor1, tensor2):\n",
    "        return torch.cat((tensor1, tensor2),1)\n",
    "    \n",
    "    def u_net(self, image):\n",
    "        #downsampling\n",
    "        tensor_1 = self.floor_1(image) #1st floor\n",
    "        tensor_2 = self.downscale_1(tensor_1) \n",
    "        tensor_2 = self.floor_2(tensor_2) #2nd floor\n",
    "        tensor_3 = self.downscale_2(tensor_2)\n",
    "        #cellar\n",
    "        tensor_3 = self.floor_3(tensor_3) #3d floor\n",
    "        #upscale\n",
    "        tensor_2_up = self.upscale_2(tensor_3)\n",
    "        #concatenation\n",
    "        concat_2 = self.concat(tensor_2, tensor_2_up) #2nd floor\n",
    "        tensor_2_up = self.floor_2_up(concat_2)\n",
    "        #upscale\n",
    "        tensor_1_up = self.upscale_1(tensor_2_up)\n",
    "        #concatenation \n",
    "        concat_1 = self.concat(tensor_1, tensor_1_up) #1st floor\n",
    "        mask = self.floor_1_up(concat_1)\n",
    "        return mask\n",
    "    \n",
    "    def forward(self, image):\n",
    "        mask = self.u_net(image)\n",
    "        softmax = nn.Softmax()\n",
    "        mask = softmax(mask)\n",
    "        artificial_image = self.u_net(mask)\n",
    "        return mask, artificial_image\n",
    "\n",
    "wnet=W_Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0HEsgadlRyyb"
   },
   "outputs": [],
   "source": [
    "for _, image in enumerate(train_loader):\n",
    "    print(image.shape)\n",
    "    optimizer.zero_grad()\n",
    "    input = image\n",
    "    #input=input[None,None,:]\n",
    "    print(input.size())\n",
    "    mask, output=wnet.forward(input)\n",
    "    print(mask.size())\n",
    "    print(output.size())\n",
    "    plt.imshow(input[0][0].detach().numpy())\n",
    "    plt.show()\n",
    "    plt.imshow(mask[0][0].detach().numpy())\n",
    "    plt.show()\n",
    "    plt.imshow(output[0][0].detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JqQTXIxaRyyb"
   },
   "outputs": [],
   "source": [
    "def global_loss(fake, real):\n",
    "    return (F.binary_cross_entropy(fake, real))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TK4lhzbgRyyc",
    "tags": []
   },
   "source": [
    "### Train block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fm8x8WsERyyc"
   },
   "outputs": [],
   "source": [
    "learning_rate=0.01\n",
    "optimizer=torch.optim.SGD(wnet.parameters(), lr=learning_rate)\n",
    "train_loader=DataLoader(dataset=SEM_images, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Om9VCXFQRyyc"
   },
   "outputs": [],
   "source": [
    "def train(criterion = global_loss, model=wnet, optimizer=optimizer, num_epochs=2):\n",
    "    best_acc = 0.0\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "        print('-' * 10)\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "        for _, image in enumerate(train_loader):\n",
    "            print(image.shape)\n",
    "            optimizer.zero_grad()\n",
    "            mask, outputs = model(image)\n",
    "            print(output.shape)\n",
    "            loss = criterion(output, image)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "    return\n",
    "\n",
    "train(criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "Ceramic_grain_segmentation.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
